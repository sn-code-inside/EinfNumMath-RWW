{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bfe673",
   "metadata": {},
   "source": [
    "## 6.2 Das CG-Verfahren für symmetrisch positiv definite Gleichungssysteme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ac0f2-21f3-4c44-8978-0c72e8a16209",
   "metadata": {},
   "source": [
    "**Implementierung 6.1: CG-Verfahren**\n",
    "\n",
    "Wir implementieren das CG-Verfahren mit Hilfe der `numpy` Routinen für Matrix-Vektor- und Skalarprodukte. Dabei achten wir darauf, dass wir jedes Produkt nur einmal pro Iteration berechnen und wir das Ergebnis wieder verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_verfahren(A, b, x, it=100, tol=1e-5):\n",
    "    x = x.copy()\n",
    "    r = b - A.dot(x)\n",
    "    d = r.copy()\n",
    "    nrm_r2 = r.dot(r)\n",
    "    tol = tol**2\n",
    "    \n",
    "    for i in range(1, it + 1):\n",
    "        if nrm_r2 < tol:\n",
    "            break\n",
    "        Ad = A.dot(d)\n",
    "        dAd = d.dot(Ad)\n",
    "        alpha = nrm_r2 / dAd\n",
    "        x[:] += alpha * d\n",
    "        r[:] -= alpha * Ad\n",
    "        nrm_r2_neu = r.dot(r)\n",
    "        \n",
    "        beta = nrm_r2_neu / nrm_r2\n",
    "        d[:] = r + beta * d\n",
    "        nrm_r2 = nrm_r2_neu\n",
    "    else:\n",
    "        print(f'Das CG-Verfahren ist nach {i} Iterationen nicht konvergiert.')\n",
    "    return x, i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e141b19-090b-41e7-a280-93ce79c33bf0",
   "metadata": {},
   "source": [
    "Um das Verfahren mit den bisherigen Iterationsverfahren zum Lösen linearer Gleichungssysteme zu vergleichen, betrachten wir zunächst wieder die Modellmatrix aus Beispiel 3.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a094f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    m = i * 10\n",
    "    n = m**2\n",
    "    N = np.diag(np.ones(m - 1), 1) + np.diag(np.ones(m - 1), -1)\n",
    "    B = 4 * np.eye(m) - N\n",
    "    A = np.kron(np.eye(m), B) - np.kron(N, np.eye(m))\n",
    "    b = np.ones(n)\n",
    "    x0 = np.zeros(n)\n",
    "    \n",
    "    t = time.perf_counter()\n",
    "    x, m = cg_verfahren(A, b, x0, it=int(1e6), tol=1e-6)\n",
    "    t = time.perf_counter() - t\n",
    "    \n",
    "    res = np.linalg.norm(b - np.dot(A, x))\n",
    "    print(f'CG-Verfahren: n = {n:05d}, Schritte = {m:05d} Zeit = {t:07.4f}sec, res = {res:4.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3803c226",
   "metadata": {},
   "source": [
    "Da die Implementierung des CG-Verfahrens keine Zugriffe auf Teil-Matrizen oder Vektoren benötigt, ist unsere Implementierung sogar deutlich effizienter als das SOR-Verfahren, selbst bei optimaler Wahl des Relaxationsparameter.\n",
    "\n",
    "## 6.3 Vorkonditioniertes CG-Verfahren\n",
    "\n",
    "**CG-Verfahren mit Jacobi Vorkonditionierung**\n",
    "\n",
    "Um das vorkonditionierte CG-Verfahren zu implementieren, müssen wir eine Wahl für die Vorkonditionierung $P\\approx A^{-1}$ treffen. Die einfachste Wahl ist hier die Jacobi-Vorkonditionierung mit $P=D^{-1}$, wobei $D$ der Diagonalteil von A ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f385ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_verfahren_jacobi_vorkon(A, b, x, it=100, tol=1e-5):\n",
    "    x = x.copy()\n",
    "    r = b.copy() - A.dot(x)\n",
    "    P_inv = 1 / np.diag(A)\n",
    "    p = P_inv * r.copy()\n",
    "    d = p.copy()\n",
    "    rp = r.dot(p)\n",
    "    tol = tol**2\n",
    "    \n",
    "    for i in range(1, it + 1):\n",
    "        if abs(rp) < tol:\n",
    "            break\n",
    "        Ad = A.dot(d)\n",
    "        alpha = rp / d.dot(Ad)\n",
    "        x[:] += alpha * d\n",
    "        r[:] -= alpha * Ad\n",
    "        p[:] = P_inv * r\n",
    "        rp_neu = r.dot(p)\n",
    "        beta = rp_neu / rp\n",
    "        d[:] = p + beta * d\n",
    "        rp = rp_neu\n",
    "    else:\n",
    "        print(f'Das Jacobi-vorkonditionierte CG-Verfahren ist nach {i} Iterationen nicht konvergiert.')\n",
    "    return x, i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c15c7-b4f5-4a31-b10a-50df71aa0418",
   "metadata": {},
   "source": [
    "#### Beispiel 6.10\n",
    "\n",
    "Angewandt auf die Modellmatrix aus Beispiel 3.50 ergibt das Jacobi-vorkonditionierte CG-Verfahren folgende Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    m = i * 10\n",
    "    n = m**2\n",
    "    N = np.diag(np.ones(m - 1), 1) + np.diag(np.ones(m - 1), -1)\n",
    "    B = 4 * np.eye(m) - N\n",
    "    A = np.kron(np.eye(m), B) - np.kron(N, np.eye(m))\n",
    "    b = np.ones(n)\n",
    "    x0 = np.zeros(n)\n",
    "    \n",
    "    t = time.perf_counter()\n",
    "    x, m = cg_verfahren_jacobi_vorkon(A, b, x0, it=int(1e6), tol=1e-6)\n",
    "    t = time.perf_counter() - t\n",
    "    \n",
    "    res = np.linalg.norm(b - np.dot(A, x))\n",
    "    print(f'Jacobi-vorkonditionierte CG-Verfahren: n = {n:05d}, Schritte = {m:05d} Zeit = {t:07.4f}sec, res = {res:4.2e}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cae50-2725-4ab5-ad05-62d29f584ccd",
   "metadata": {},
   "source": [
    "Die Jacobi-Vorkonditionierung hat uns in diesem Fall also nicht wesentlich geholfen. Um die SSOR-Vorkonditionierung zu implementieren, widmen wir uns zunächst dem vorkonditionierten CG-Verfahren mit einem allgemeinen Vorkonditionerer $P$. Dabei verstecken wir das Anwenden von $P^{-1}$ in `np.linalg.solve(P, r)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_verfahren_vorkon(A, P, b, x, it=100, tol=1e-5):\n",
    "    x = x.copy()\n",
    "    r = b.copy() - A.dot(x)\n",
    "    p = np.linalg.solve(P, r)\n",
    "    d = p.copy()\n",
    "    rp = r.dot(p)\n",
    "    tol = tol**2\n",
    "    \n",
    "    for i in range(1, it + 1):\n",
    "        if abs(rp) < tol:\n",
    "            break\n",
    "        Ad = A.dot(d)\n",
    "        alpha = rp / d.dot(Ad)\n",
    "        x[:] += alpha * d\n",
    "        r[:] -= alpha * Ad \n",
    "        p[:] = np.linalg.solve(P, r)\n",
    "        rp_neu = r.dot(p)\n",
    "\n",
    "        beta = rp_neu / rp\n",
    "        d[:] = p + beta * d\n",
    "        rp = rp_neu\n",
    "    else:\n",
    "        print(f'Das vorkonditionierte CG-Verfahren ist nach {i} Iterationen nicht konvergiert.')\n",
    "    return x, i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f8a13-f0a0-420f-b651-2e8711ec1a4a",
   "metadata": {},
   "source": [
    "Angewandt auf die Modellmatrix ergibt sich damit mit der optimalen Wahl von $\\omega=2 - \\frac{2\\pi}{\\sqrt{n}}$ die Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 9):\n",
    "    m = i * 10\n",
    "    n = m**2\n",
    "    N = np.diag(np.ones(m - 1), 1) + np.diag(np.ones(m - 1), -1)\n",
    "    B = 4 * np.eye(m) - N\n",
    "    A = np.kron(np.eye(m), B) - np.kron(N, np.eye(m))\n",
    "    b = np.ones(n)\n",
    "    x0 = np.zeros(n)\n",
    "    b = np.ones(n)\n",
    "    x0 = np.zeros(n)\n",
    "    \n",
    "    omega = 2 - 2 * np.pi / np.sqrt(n)\n",
    "    D = np.diag(np.diag(A))\n",
    "    D1 = np.diag(1 / np.diag(A))\n",
    "    L = np.tril(A, -1)\n",
    "    R = np.triu(A, 1)\n",
    "    P = (D + omega * L) @ D1 @ (D + omega * R)\n",
    "    \n",
    "    t = time.perf_counter()\n",
    "    x, m = cg_verfahren_vorkon(A, P, b, x0, it=int(1e6), tol=1e-6)\n",
    "    t = time.perf_counter() - t\n",
    "    \n",
    "    res = np.linalg.norm(b - np.dot(A, x))\n",
    "    print(f'Das SSOR-vorkonditionierte CG-Verfahren: n = {n:04d}, Schritte = {m:05d} Zeit = {t:07.4f}sec, res = {res:4.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac3831-fffd-4a2b-82f1-5b4695fb9b74",
   "metadata": {},
   "source": [
    "Die Konvergenz hat sich also wesentlich verbessert! Die Anzahl der notwendigen Schritte wächst auch nur sehr langsam. Allerdings ist das Lösen des Systems `pneu = np.linalg.solve(P, rneu)` hier wesentlich teurer, sodass die Rechenzeit jedes Schrittes aufwändiger ist. Es zeigt sich also, dass die Kosten des Anwenden des Vorkonditionierers eine wesentliche Rolle bei der Wahl spielten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37170e31-4327-40ad-b4a5-f8f2ea5e662f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
